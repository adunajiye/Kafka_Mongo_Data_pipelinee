# Kafka_Mongo_Data_pipelinee

# Project Overview 
For this project i have been cooking up a robust,scalable and fault tolerant data pipeline which has been a complex task involves muiltiple tools and technologies. 
We will explore an end to end data engineering project that uses docker, Apache Airflow,Apache Kafka,Apache spark,Mongo DB. 

# Data Stack
Apache Airflow: An open source platform used to schedule and monitor workflows

Apache Kafka: A distributed streaming platform designed for fault tolerance, high throughput and scalibility

Apache Spark: A unified analytics engine for big data processing with built in modules for streaming, SQL Machine learning and graph processing.

Docker: A containerization tool that allows for isolated, consistent and easily deployable applications

Mongo DB:

PostgreSQL: Ana open source relational database that focuses on extensibility and SQL compliance 

Linux: DigitalOcean Droplets
