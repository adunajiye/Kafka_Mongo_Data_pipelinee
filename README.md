# Kafka_Mongo_Data_pipelinee

# Project Overview 
For this project i have been cooking up a robust,scalable and fault tolerant data pipeline which has been a complex task involves muiltiple tools and technologies. 
We will explore an end to end data engineering project that uses docker, Apache Airflow,Apache Kafka,Apache spark,Mongo DB. 

# Data Stack
1. Apache Airflow: An open source platform used to schedule and monitor workflows

2. Apache Kafka: A distributed streaming platform designed for fault tolerance, high throughput and scalibility

3. Apache Spark: A unified analytics engine for big data processing with built in modules for streaming, SQL Machine learning and graph processing.

4. Docker: A containerization tool that allows for isolated, consistent and easily deployable applications

5. PostgreSQL: Ana open source relational database that focuses on extensibility and SQL compliance 

6. Linux: DigitalOcean Droplets
